% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Zagent.R
\name{Agent}
\alias{Agent}
\title{Agent Class for LLM Interactions}
\description{
An R6 class representing an agent that interacts with language models.
Each agent maintains its own memory, persona, and model configuration for
consistent and contextual interactions with a language model.

In this design, you can enable/disable:
\itemize{
  \item \strong{Dynamic Summarization:} When \code{enable_summarization = TRUE}, the agent automatically
        summarizes its memory once it exceeds \code{summarization_threshold}. This keeps the agent's
        memory concise and avoids large prompt contexts.
  \item \strong{Auto-Injection of Conversation:} When \code{auto_inject_conversation = TRUE}, the agent
        checks if \code{{\{conversation\}}} is in the user-provided prompt. If it's missing, the agent
        automatically prepends a short block containing the entire conversation memory.
}
}
\section{Public fields}{
\if{html}{\out{<div class="r6-fields">}}
\describe{
\item{\code{id}}{Unique ID for this Agent.}

\item{\code{context_length}}{Maximum number of conversation turns stored in memory.}

\item{\code{model_config}}{The \code{llm_config} specifying which LLM to call.}

\item{\code{memory}}{A list of speaker/text pairs that the agent has memorized.}

\item{\code{persona}}{Named list for additional agent-specific details (e.g., role, style).}

\item{\code{enable_summarization}}{If TRUE, agent will summarize memory once it exceeds a threshold.}

\item{\code{summarization_threshold}}{The max memory length before summarization. Defaults to \code{context_length}.}

\item{\code{auto_inject_conversation}}{If TRUE, automatically prepend conversation if missing in the prompt.}
}
\if{html}{\out{</div>}}
}
\section{Methods}{
\subsection{Public methods}{
\itemize{
\item \href{#method-Agent-new}{\code{Agent$new()}}
\item \href{#method-Agent-add_memory}{\code{Agent$add_memory()}}
\item \href{#method-Agent-maybe_summarize_memory}{\code{Agent$maybe_summarize_memory()}}
\item \href{#method-Agent-generate_prompt}{\code{Agent$generate_prompt()}}
\item \href{#method-Agent-call_llm_agent}{\code{Agent$call_llm_agent()}}
\item \href{#method-Agent-generate}{\code{Agent$generate()}}
\item \href{#method-Agent-think}{\code{Agent$think()}}
\item \href{#method-Agent-respond}{\code{Agent$respond()}}
\item \href{#method-Agent-reset_memory}{\code{Agent$reset_memory()}}
\item \href{#method-Agent-clone}{\code{Agent$clone()}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-Agent-new"></a>}}
\if{latex}{\out{\hypertarget{method-Agent-new}{}}}
\subsection{Method \code{new()}}{
Create a new Agent instance.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Agent$new(
  id,
  context_length = 5,
  persona = NULL,
  model_config,
  enable_summarization = TRUE,
  auto_inject_conversation = TRUE
)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{id}}{Character. The agent's unique identifier.}

\item{\code{context_length}}{Numeric. The maximum number of messages stored (default = 5).}

\item{\code{persona}}{A named list of persona details (replaces old "knowledge" concept).}

\item{\code{model_config}}{An \code{llm_config} object (from LLMR) specifying LLM settings (API, model, etc.).}

\item{\code{enable_summarization}}{Logical. If TRUE, memory is auto-summarized when threshold exceeded.}

\item{\code{auto_inject_conversation}}{Logical. If TRUE, auto-append conversation memory to prompt
if \code{{\{conversation\}}} is missing. Defaults to TRUE.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
A new \code{Agent} object.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-Agent-add_memory"></a>}}
\if{latex}{\out{\hypertarget{method-Agent-add_memory}{}}}
\subsection{Method \code{add_memory()}}{
Add a new message to the agent's memory. If summarization is enabled and
the memory size exceeds \code{summarization_threshold}, the agent will summarize
the entire memory into a single "summary" message.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Agent$add_memory(speaker, text)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{speaker}}{Character. The speaker name or ID.}

\item{\code{text}}{Character. The message content.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-Agent-maybe_summarize_memory"></a>}}
\if{latex}{\out{\hypertarget{method-Agent-maybe_summarize_memory}{}}}
\subsection{Method \code{maybe_summarize_memory()}}{
Summarize the entire memory via a call to the underlying LLM, replacing
all past messages with a single "summary" line.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Agent$maybe_summarize_memory()}\if{html}{\out{</div>}}
}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-Agent-generate_prompt"></a>}}
\if{latex}{\out{\hypertarget{method-Agent-generate_prompt}{}}}
\subsection{Method \code{generate_prompt()}}{
Internal helper to prepare final prompt by substituting placeholders.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Agent$generate_prompt(template, replacements = list())}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{template}}{Character. The prompt template.}

\item{\code{replacements}}{A named list of placeholder values.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
Character. The prompt with placeholders replaced.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-Agent-call_llm_agent"></a>}}
\if{latex}{\out{\hypertarget{method-Agent-call_llm_agent}{}}}
\subsection{Method \code{call_llm_agent()}}{
Make a low-level call to the LLM (via \code{call_llm()}) with the final prompt.
If \code{persona} is set, a system message is prepended to help the LLM assume
the agent's role/personality.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Agent$call_llm_agent(prompt, verbose = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{prompt}}{Character. The final prompt text.}

\item{\code{verbose}}{Logical. If TRUE, prints debug info. Default FALSE.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
A list with:
\itemize{
  \item{text}{The text output from the LLM.}
  \item{tokens_sent}{Number of tokens sent (if provider returns usage).}
  \item{tokens_received}{Number of tokens in the LLM response (if provider returns usage).}
  \item{full_response}{Raw response from the LLM (list).}
  }
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-Agent-generate"></a>}}
\if{latex}{\out{\hypertarget{method-Agent-generate}{}}}
\subsection{Method \code{generate()}}{
A general method to generate a response from the LLM using a prompt template
and optional replacements. This method:
\enumerate{
  \item Substitutes placeholders in the prompt.
  \item Calls the LLM.
  \item Saves the newly generated text to memory.
  \item Returns the response with usage info.
}
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Agent$generate(prompt_template, replacements = list(), verbose = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{prompt_template}}{Character. The prompt template.}

\item{\code{replacements}}{A named list of placeholder values. (e.g. \code{list(topic = "Math problem")})}

\item{\code{verbose}}{Logical. If TRUE, prints extra info. Default FALSE.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
A list with fields \code{text}, \code{tokens_sent}, \code{tokens_received}, \code{full_response}.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-Agent-think"></a>}}
\if{latex}{\out{\hypertarget{method-Agent-think}{}}}
\subsection{Method \code{think()}}{
Have the agent produce an "internal" thought about a \code{topic}, using the entire memory.
By default, if \code{auto_inject_conversation} is TRUE and the template lacks \code{{\{conversation\}}}
the agent prepends a short block with the conversation.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Agent$think(topic, prompt_template, replacements = list(), verbose = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{topic}}{Character. A label describing the thought (for logging).}

\item{\code{prompt_template}}{Character. The prompt template, which may include placeholders like \code{{\{conversation\}}}.}

\item{\code{replacements}}{Named list for additional placeholders.}

\item{\code{verbose}}{Logical. If TRUE, prints debug info.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
A list with the LLM's response text, tokens sent/received, and the full LLM response.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-Agent-respond"></a>}}
\if{latex}{\out{\hypertarget{method-Agent-respond}{}}}
\subsection{Method \code{respond()}}{
Have the agent produce a "public" response (or output) about a \code{topic}.
By default, if \code{auto_inject_conversation} is TRUE and the template lacks \code{{\{conversation\}}},
the agent automatically prepends the entire memory.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Agent$respond(topic, prompt_template, replacements = list(), verbose = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{topic}}{Character. A short label for the question/issue being responded to.}

\item{\code{prompt_template}}{Character. The prompt template.}

\item{\code{replacements}}{A named list for placeholder substitution.}

\item{\code{verbose}}{Logical. If TRUE, prints extra info.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
A list with \code{text}, \code{tokens_sent}, \code{tokens_received}, \code{full_response}.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-Agent-reset_memory"></a>}}
\if{latex}{\out{\hypertarget{method-Agent-reset_memory}{}}}
\subsection{Method \code{reset_memory()}}{
Reset the agent's memory (clear any stored conversation context).
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Agent$reset_memory()}\if{html}{\out{</div>}}
}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-Agent-clone"></a>}}
\if{latex}{\out{\hypertarget{method-Agent-clone}{}}}
\subsection{Method \code{clone()}}{
The objects of this class are cloneable with this method.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Agent$clone(deep = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{deep}}{Whether to make a deep clone.}
}
\if{html}{\out{</div>}}
}
}
}
